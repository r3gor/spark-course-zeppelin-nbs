{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persistencia y particionado\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%sh\n",
    "cd ../../../dev\n",
    "ls\n",
    "# ls -all zeppelin\n",
    "# cd zeppelin\n",
    "# cd notebook\n",
    "# ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%sh\n",
    "cd conf\n",
    "ls -all\n",
    "cat *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%sh\n",
    "ls -all /home/vagrant/zeppelin\n",
    "cat /home/vagrant/zeppelin/README*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistencia\n",
    "\n",
    "Problema al usar un RDD varias veces:\n",
    "\n",
    "-   Spark recomputa el RDD y sus dependencias cada vez que se ejecuta una acción\n",
    "-   Muy costoso (especialmente en problemas iterativos)\n",
    "\n",
    "Solución\n",
    "\n",
    "-   Conservar el RDD en memoria y/o disco\n",
    "-   Métodos `cache()` o `persist()`\n",
    "\n",
    "#### Niveles de persistencia (definidos en [`pyspark.StorageLevel`](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.StorageLevel))\n",
    " Nivel                | Espacio  | CPU     | Memoria/Disco   | Descripción\n",
    " :------------------: | :------: | :-----: | :-------------: | ------------------\n",
    " MEMORY_ONLY          |   Alto   |   Bajo  |     Memoria     | Guarda el RDD como un objeto Java no serializado en la JVM. Si el RDD no cabe en memoria, algunas particiones no se *cachearán* y serán recomputadas \"al vuelo\" cada vez que se necesiten. Nivel por defecto en Java y Scala.\n",
    " MEMORY_ONLY_SER      |   Bajo   |   Alto  |     Memoria     | Guarda el RDD como un objeto Java serializado (un *byte array* por partición). Nivel por defecto en Python, usando [`pickle`](http://docs.python.org/2/library/pickle.html).\n",
    " MEMORY_AND_DISK      |   Alto   |   Medio |     Ambos       | Guarda el RDD como un objeto Java no serializado en la JVM. Si el RDD no cabe en memoria, las particiones que no quepan se guardan en disco y se leen del mismo cada vez que se necesiten\n",
    " MEMORY_AND_DISK_SER  |   Bajo   |   Alto  |     Ambos       | Similar a MEMORY_AND_DISK pero usando objetos serializados.\n",
    " DISK_ONLY            |   Bajo   |   Alto  |     Disco       | Guarda las particiones del RDD solo en disco.\n",
    " OFF_HEAP             |   Bajo   |   Alto  |   Memoria       | Guarda el RDD serializado usando memoria *off-heap* (fuera del heap de la JVM) lo que puede reducir el overhead del recolector de basura\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "#### Nivel de persistencia\n",
    "\n",
    "-   En Scala y Java, el nivel por defecto es MEMORY\\_ONLY\n",
    "\n",
    "-   En Python, los datos siempre se serializan (por defecto como objetos *pickled*)\n",
    "\n",
    "    -   Los niveles MEMORY_ONLY, MEMORY_AND_DISK son equivalentes a MEMORY_ONLY_SER, MEMORY_AND_DISK_SER\n",
    "    - Es posible especificar serialización [`marshal`](https://docs.python.org/2/library/marshal.html#module-marshal) al crear el SparkContext\n",
    "    \n",
    "```python\n",
    "sc = SparkContext(master=\"local\", appName=\"Mi app\", serializer=pyspark.MarshalSerializer())\n",
    "```\n",
    "    \n",
    "#### Recuperación de fallos\n",
    "\n",
    "-   Si falla un nodo con datos almacenados, el RDD se recomputa\n",
    "\n",
    "    -   Añadiendo `_2` al nivel de persistencia, se guardan 2 copias del RDD\n",
    "        \n",
    "#### Gestión de la cache\n",
    "\n",
    "-   Algoritmo LRU para gestionar la cache\n",
    "\n",
    "    -   Para niveles *solo memoria*, los RDDs viejos se eliminan y se recalculan\n",
    "    -   Para niveles *memoria y disco*, las particiones que no caben se escriben a disco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(1000), 10)\n",
    "\n",
    "print(rdd.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd.persist(StorageLevel.MEMORY_AND_DISK_SER_2)\n",
    "\n",
    "print(rdd.is_cached)\n",
    "\n",
    "print(\"Nivel de persistencia de rdd: {0} \".format(rdd.getStorageLevel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda x: x*x)\n",
    "print(rdd2.is_cached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd2.cache() # Nivel por defecto\n",
    "print(rdd2.is_cached)\n",
    "print(\"Nivel de persistencia de rdd2: {0}\".format(rdd2.getStorageLevel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd2.unpersist() # Sacamos rdd2 de la cache\n",
    "print(rdd2.is_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionado\n",
    "\n",
    "El número de particiones es función del tamaño del cluster o el número de bloques del fichero en HDFS\n",
    "\n",
    "-   Es posible ajustarlo al crear u operar sobre un RDD\n",
    "\n",
    "-   El paralelismo de RDDs que derivan de otros depende del de sus RDDs padre\n",
    "\n",
    "-   Dos funciones útiles:\n",
    "\n",
    "    -   `rdd.getNumPartitions()` devuelve el número de particiones del RDD\n",
    "    -   `rdd.glom()` devuelve un nuevo RDD juntando los elementos de cada partición en una lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 2, 4, 1], 4)\n",
    "pairs = rdd.map(lambda x: (x, x))\n",
    "\n",
    "print(\"RDD pairs = {0}\".format(\n",
    "        pairs.collect()))\n",
    "print(\"Particionado de pairs: {0}\".format(\n",
    "        pairs.glom().collect()))\n",
    "print(\"Número de particiones de pairs = {0}\".format(\n",
    "        pairs.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# Reducción manteniendo el número de particiones\n",
    "print(\"Reducción con 4 particiones: {0}\".format(\n",
    "        pairs.reduceByKey(lambda x, y: x+y).glom().collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# Reducción modificando el número de particiones\n",
    "print(\"Reducción con 2 particiones: {0}\".format(\n",
    "       pairs.reduceByKey(lambda x, y: x+y, 2).glom().collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de reparticionado\n",
    "- `repartition(n)` devuelve un nuevo RDD que tiene exactamente `n` particiones\n",
    "- `coalesce(n)` más eficiente que `repartition`, minimiza el movimiento de datos\n",
    "    - Solo permite reducir el número de particiones\n",
    "- `partitionBy(n,[partitionFunc])` Particiona por clave, usando una función de particionado (por defecto, un hash de la clave)\n",
    "    - Solo para RDDs clave/valor\n",
    "    - Asegura que los pares con la misma clave vayan a la misma partición\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pairs5 = pairs.repartition(5)\n",
    "print(\"pairs5 con {0} particiones: {1}\".format(\n",
    "        pairs5.getNumPartitions(),\n",
    "        pairs5.glom().collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pairs2 = pairs5.coalesce(2)\n",
    "print(\"pairs2 con {0} particiones: {1}\".format(\n",
    "        pairs2.getNumPartitions(),\n",
    "        pairs2.glom().collect()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pairs_clave = pairs2.partitionBy(3)\n",
    "print(\"Particionado por clave ({0} particiones): {1}\".format(\n",
    "        pairs_clave.getNumPartitions(),\n",
    "        pairs_clave.glom().collect())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
