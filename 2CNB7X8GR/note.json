{
  "paragraphs": [
    {
      "text": "%md\n# RDDs con pares clave/valor (aka *Pair RDDs*)\n\n-   Tipos de datos muy usados en Big Data (MapReduce)\n\n-   Spark dispone de operaciones especiales para su manejo",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:37 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eRDDs con pares clave/valor (aka \u003cem\u003ePair RDDs\u003c/em\u003e)\u003c/h1\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003eTipos de datos muy usados en Big Data (MapReduce)\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eSpark dispone de operaciones especiales para su manejo\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499539001715_963360055",
      "id": "20170708-183641_1609794276",
      "dateCreated": "Jul 8, 2017 6:36:41 PM",
      "dateStarted": "Jul 13, 2017 11:54:32 AM",
      "dateFinished": "Jul 13, 2017 11:54:32 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Creación de *Pair RDDs*\nLos RDDs clave/valor pueden crearse a partir de una lista de tuplas, a partir de otro RDD o mediante un zip de dos RDDs.",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:39 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eCreación de \u003cem\u003ePair RDDs\u003c/em\u003e\u003c/h3\u003e\n\u003cp\u003eLos RDDs clave/valor pueden crearse a partir de una lista de tuplas, a partir de otro RDD o mediante un zip de dos RDDs.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499539111934_2071021490",
      "id": "20170708-183831_1559169513",
      "dateCreated": "Jul 8, 2017 6:38:31 PM",
      "dateStarted": "Jul 13, 2017 11:54:41 AM",
      "dateFinished": "Jul 13, 2017 11:54:41 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   A partir de una lista de tuplas",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:40 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eA partir de una lista de tuplas\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499539122534_-2084819945",
      "id": "20170708-183842_742913676",
      "dateCreated": "Jul 8, 2017 6:38:42 PM",
      "dateStarted": "Jul 8, 2017 6:40:01 PM",
      "dateFinished": "Jul 8, 2017 6:40:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nprdd \u003d sc.parallelize([(\u0027a\u0027,2), (\u0027b\u0027,5), (\u0027a\u0027,3)])\nprint(prdd.collect())\n\nprdd \u003d sc.parallelize(zip([\u0027a\u0027, \u0027b\u0027, \u0027c\u0027], range(3)))\nprint(prdd.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:41 AM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, 2), (\u0027b\u0027, 5), (\u0027a\u0027, 3)]\n[(\u0027a\u0027, 0), (\u0027b\u0027, 1), (\u0027c\u0027, 2)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d1",
            "http://10.0.2.15:4040/jobs/job?id\u003d2"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499539201566_151017733",
      "id": "20170708-184001_776040480",
      "dateCreated": "Jul 8, 2017 6:40:01 PM",
      "dateStarted": "Jun 3, 2023 4:09:42 AM",
      "dateFinished": "Jun 3, 2023 4:10:53 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nval prdd \u003d sc.parallelize(List((\u0027a\u0027,2), (\u0027b\u0027,5), (\u0027a\u0027,3)))\nprdd.collect()\n\nval prdd \u003d sc.parallelize(List(\u0027a\u0027, \u0027b\u0027, \u0027c\u0027) zip (1 to 3).toList)\nprdd.collect()",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:42 AM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "prdd: org.apache.spark.rdd.RDD[(Char, Int)] \u003d ParallelCollectionRDD[1] at parallelize at \u003cconsole\u003e:29\nres0: Array[(Char, Int)] \u003d Array((a,2), (b,5), (a,3))\nprdd: org.apache.spark.rdd.RDD[(Char, Int)] \u003d ParallelCollectionRDD[6] at parallelize at \u003cconsole\u003e:29\nres1: Array[(Char, Int)] \u003d Array((a,1), (b,2), (c,3))\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d0",
            "http://10.0.2.15:4040/jobs/job?id\u003d4"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499539256199_-1796688468",
      "id": "20170708-184056_21645820",
      "dateCreated": "Jul 8, 2017 6:40:56 PM",
      "dateStarted": "Jun 3, 2023 4:09:47 AM",
      "dateFinished": "Jun 3, 2023 4:10:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   A partir de otro RDD",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:46 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eA partir de otro RDD\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499539320187_876855018",
      "id": "20170708-184200_538389667",
      "dateCreated": "Jul 8, 2017 6:42:00 PM",
      "dateStarted": "Jul 8, 2017 6:58:40 PM",
      "dateFinished": "Jul 8, 2017 6:58:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Ejemplo usando un fichero\n# Para cada línea ontenemos una tupla, siendo el primer elemento\n# la primera palabra de la línes, y el segundo la línea completa\nlinesrdd \u003d sc.textFile(\"../datos/quijote.txt\", use_unicode\u003dFalse)\nprdd \u003d linesrdd.map(lambda x: (x.split(\" \")[0], x))\n\nprint(\u0027Par (1ª palabra, línea): {0}\\n\u0027.format(prdd.takeSample(False, 1)))\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:46 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Par (1ª palabra, línea): [(\u0027te\u0027, \u0027te hago saber que es mi se\\xc3\\xb1or don Quijote tan cat\\xc3\\xb3lico y escrupuloso\u0027)]\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d3",
            "http://10.0.2.15:4040/jobs/job?id\u003d5"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499539830723_494133842",
      "id": "20170708-185030_1311976050",
      "dateCreated": "Jul 8, 2017 6:50:30 PM",
      "dateStarted": "Jun 3, 2023 4:09:47 AM",
      "dateFinished": "Jun 3, 2023 4:10:58 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Usando keyBy(f): Crea tuplas de los elementos del RDD usando f para obtener la clave.\nnrdd \u003d sc.parallelize(xrange(2,5))\nprdd \u003d nrdd.keyBy(lambda x: x*x)\n\nprint(prdd.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:47 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(4, 2), (9, 3), (16, 4)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d6"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499539883195_1629051153",
      "id": "20170708-185123_228837373",
      "dateCreated": "Jul 8, 2017 6:51:23 PM",
      "dateStarted": "Jun 3, 2023 4:10:53 AM",
      "dateFinished": "Jun 3, 2023 4:10:58 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# zipWithIndex(): Zipea el RDD con los índices de sus elementos.\nrdd \u003d sc.parallelize([\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027, \u0027f\u0027, \u0027g\u0027, \u0027h\u0027], 3)\nprdd \u003d rdd.zipWithIndex()\nprint(rdd.glom().collect())\n\nprint(prdd.collect())\n\n# Este método dispara un Spark job cuando el RDD tiene más de una partición.",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:47 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[[\u0027a\u0027, \u0027b\u0027], [\u0027c\u0027, \u0027d\u0027], [\u0027e\u0027, \u0027f\u0027, \u0027g\u0027, \u0027h\u0027]]\n[(\u0027a\u0027, 0), (\u0027b\u0027, 1), (\u0027c\u0027, 2), (\u0027d\u0027, 3), (\u0027e\u0027, 4), (\u0027f\u0027, 5), (\u0027g\u0027, 6), (\u0027h\u0027, 7)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d7",
            "http://10.0.2.15:4040/jobs/job?id\u003d8",
            "http://10.0.2.15:4040/jobs/job?id\u003d9"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499540151612_1964904650",
      "id": "20170708-185551_1592986113",
      "dateCreated": "Jul 8, 2017 6:55:51 PM",
      "dateStarted": "Jun 3, 2023 4:10:58 AM",
      "dateFinished": "Jun 3, 2023 4:10:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# zipWithUniqueId(): Zipea el RDD con identificadores únicos (long) para cada elemento.\n# Los elementos en la partición k-ésima obtienen los ids k, n+k, 2*n+k,... siendo n \u003d nº de particiones\n# No dispara un trabajo Spark\nrdd \u003d sc.parallelize([\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027, \u0027f\u0027, \u0027g\u0027, \u0027h\u0027], 3)\nprint(\"Particionado del RDD: {0}\".format(rdd.glom().collect()))\nprdd \u003d rdd.zipWithUniqueId()\n\nprint(prdd.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:47 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Particionado del RDD: [[\u0027a\u0027, \u0027b\u0027], [\u0027c\u0027, \u0027d\u0027], [\u0027e\u0027, \u0027f\u0027, \u0027g\u0027, \u0027h\u0027]]\n[(\u0027a\u0027, 0), (\u0027b\u0027, 3), (\u0027c\u0027, 1), (\u0027d\u0027, 4), (\u0027e\u0027, 2), (\u0027f\u0027, 5), (\u0027g\u0027, 8), (\u0027h\u0027, 11)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d10",
            "http://10.0.2.15:4040/jobs/job?id\u003d11"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499540391576_-1274916409",
      "id": "20170708-185951_183844766",
      "dateCreated": "Jul 8, 2017 6:59:51 PM",
      "dateStarted": "Jun 3, 2023 4:10:59 AM",
      "dateFinished": "Jun 3, 2023 4:10:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n- Mediante un zip de dos RDDs\n    - Los RDDs deben tener el mismo número de particiones y el mismo número de elementos en cada partición",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:48 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eMediante un zip de dos RDDs\n    \u003cul\u003e\n      \u003cli\u003eLos RDDs deben tener el mismo número de particiones y el mismo número de elementos en cada partición\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540461076_-301593637",
      "id": "20170708-190101_1648829592",
      "dateCreated": "Jul 8, 2017 7:01:01 PM",
      "dateStarted": "Jul 8, 2017 7:01:42 PM",
      "dateFinished": "Jul 8, 2017 7:01:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd1 \u003d sc.parallelize(xrange(0, 5), 2)\nrdd2 \u003d sc.parallelize(range(1000, 1005), 2)\nprdd \u003d rdd1.zip(rdd2)\n\nprint(prdd.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:48 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d12"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499540502289_253042422",
      "id": "20170708-190142_1751232574",
      "dateCreated": "Jul 8, 2017 7:01:42 PM",
      "dateStarted": "Jun 3, 2023 4:10:59 AM",
      "dateFinished": "Jun 3, 2023 4:11:00 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Transformaciones sobre un único RDD clave/valor\nSobre un único RDD clave/valor podemos efectuar transformaciones de agregación a nivel de clave y transformaciones que afectan a las claves o a los valores",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:27:35 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eTransformaciones sobre un único RDD clave/valor\u003c/h3\u003e\n\u003cp\u003eSobre un único RDD clave/valor podemos efectuar transformaciones de agregación a nivel de clave y transformaciones que afectan a las claves o a los valores\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540537900_370452133",
      "id": "20170708-190217_1787358861",
      "dateCreated": "Jul 8, 2017 7:02:17 PM",
      "dateStarted": "Jul 9, 2017 5:01:48 PM",
      "dateFinished": "Jul 9, 2017 5:01:48 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Transformaciones de agregación",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:49 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eTransformaciones de agregación\u003c/h4\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540651220_-1955584830",
      "id": "20170708-190411_1670560456",
      "dateCreated": "Jul 8, 2017 7:04:11 PM",
      "dateStarted": "Jul 8, 2017 7:39:04 PM",
      "dateFinished": "Jul 8, 2017 7:39:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `reduceByKey(func)`/`foldByKey(func)`\n    -   Devuelven un RDD, agrupando los valores asociados a la misma clave mediante `func`\n    -   Similares a `reduce` y `fold` sobre RDDs simples",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:49 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003ereduceByKey(func)\u003c/code\u003e/\u003ccode\u003efoldByKey(func)\u003c/code\u003e\n    \u003cul\u003e\n      \u003cli\u003eDevuelven un RDD, agrupando los valores asociados a la misma clave mediante \u003ccode\u003efunc\u003c/code\u003e\u003c/li\u003e\n      \u003cli\u003eSimilares a \u003ccode\u003ereduce\u003c/code\u003e y \u003ccode\u003efold\u003c/code\u003e sobre RDDs simples\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540665503_-435411278",
      "id": "20170708-190425_1242806742",
      "dateCreated": "Jul 8, 2017 7:04:25 PM",
      "dateStarted": "Jul 9, 2017 4:07:42 PM",
      "dateFinished": "Jul 9, 2017 4:07:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom operator import add\nprdd   \u003d sc.parallelize([(\u0027a\u0027, 2), (\u0027b\u0027, 5), (\u0027a\u0027, 8), (\u0027b\u0027, 6), (\u0027b\u0027, 2)]).cache()\nredrdd \u003d prdd.reduceByKey(add)\n\nprint(redrdd.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:49 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, 10), (\u0027b\u0027, 13)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d13"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499540721260_1083870184",
      "id": "20170708-190521_817452515",
      "dateCreated": "Jul 8, 2017 7:05:21 PM",
      "dateStarted": "Jun 3, 2023 4:11:00 AM",
      "dateFinished": "Jun 3, 2023 4:11:01 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `groupByKey()` agrupa valores asociados a misma clave\n    - Operación muy costosa en comunicaciones\n    - Mejor usar operaciones de reducción\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:49 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003egroupByKey()\u003c/code\u003e agrupa valores asociados a misma clave\n    \u003cul\u003e\n      \u003cli\u003eOperación muy costosa en comunicaciones\u003c/li\u003e\n      \u003cli\u003eMejor usar operaciones de reducción\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540771769_-251380355",
      "id": "20170708-190611_1823281727",
      "dateCreated": "Jul 8, 2017 7:06:11 PM",
      "dateStarted": "Jul 9, 2017 4:12:29 PM",
      "dateFinished": "Jul 9, 2017 4:12:29 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ngrouprdd \u003d prdd.groupByKey()\n\nprint(grouprdd.collect())\nprint\n\nlista \u003d [(k, list(v)) for k, v in grouprdd.collect()]\nprint(lista)",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:50 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, \u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033d4c10\u003e), (\u0027b\u0027, \u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033d4850\u003e)]\n\n[(\u0027a\u0027, [2, 8]), (\u0027b\u0027, [5, 6, 2])]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d14",
            "http://10.0.2.15:4040/jobs/job?id\u003d15"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499540796688_-1347499323",
      "id": "20170708-190636_136764461",
      "dateCreated": "Jul 8, 2017 7:06:36 PM",
      "dateStarted": "Jun 3, 2023 4:11:00 AM",
      "dateFinished": "Jun 3, 2023 4:11:02 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n- `combineByKey(createCombiner(func1), mergeValue(func2), mergeCombiners(func3))`\n    - Método general para agregación por clave, similar a `aggregate`\n    - Especifica tres funciones:\n\n     1.  `createCombiner` al recorrer los elementos de cada partición, si nos encontramos una clave nueva se crea un acumulador y se inicializa con `func1`\n\n     2.  `mergeValue` mezcla los valores de cada clave en cada partición usando `func2`\n\n     3.  `mergeCombiners` mezcla los resultados de las diferentes particiones mediante `func3`\n\n- Los valores del RDD de salida pueden tener un tipo diferente al de los valores del RDD de entrada.",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:50 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003ccode\u003ecombineByKey(createCombiner(func1), mergeValue(func2), mergeCombiners(func3))\u003c/code\u003e\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eMétodo general para agregación por clave, similar a \u003ccode\u003eaggregate\u003c/code\u003e\u003c/li\u003e\n      \u003cli\u003eEspecifica tres funciones:\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003col\u003e\n      \u003cli\u003e\n      \u003cp\u003e\u003ccode\u003ecreateCombiner\u003c/code\u003e al recorrer los elementos de cada partición, si nos encontramos una clave nueva se crea un acumulador y se inicializa con \u003ccode\u003efunc1\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n      \u003cli\u003e\n      \u003cp\u003e\u003ccode\u003emergeValue\u003c/code\u003e mezcla los valores de cada clave en cada partición usando \u003ccode\u003efunc2\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n      \u003cli\u003e\n      \u003cp\u003e\u003ccode\u003emergeCombiners\u003c/code\u003e mezcla los resultados de las diferentes particiones mediante \u003ccode\u003efunc3\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eLos valores del RDD de salida pueden tener un tipo diferente al de los valores del RDD de entrada.\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499540851874_394551752",
      "id": "20170708-190731_2066132843",
      "dateCreated": "Jul 8, 2017 7:07:31 PM",
      "dateStarted": "Jul 9, 2017 4:32:33 PM",
      "dateFinished": "Jul 9, 2017 4:32:33 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Para cada clave, obten una tupla que tenga la suma y el número de valores\nprint(prdd.collect())\nsumCount \u003d prdd.combineByKey(\n                            (lambda x: (x, 1)),\n                            (lambda x, y: (x[0]+y, x[1]+1)),\n                            (lambda x, y: (x[0]+y[0], x[1]+y[1])))\n\nprint(sumCount.collect())\n\n# Con el RDD anterior, obtenemos la media de los valores\nm \u003d sumCount.mapValues(lambda v: float(v[0])/v[1])\nprint(m.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:16:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, 7), (\u0027b\u0027, 5), (\u0027a\u0027, 8)]\n[(\u0027a\u0027, (15, 2)), (\u0027b\u0027, (5, 1))]\n[(\u0027a\u0027, 7.5), (\u0027b\u0027, 5.0)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d38",
            "http://10.0.2.15:4040/jobs/job?id\u003d39",
            "http://10.0.2.15:4040/jobs/job?id\u003d40"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541016202_-1591123642",
      "id": "20170708-191016_646406872",
      "dateCreated": "Jul 8, 2017 7:10:16 PM",
      "dateStarted": "Jun 3, 2023 4:16:52 AM",
      "dateFinished": "Jun 3, 2023 4:16:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Transformaciones sobre claves o valores\n-   `keys()` devuelve un RDD con las claves\n-   `values()` devuelve un RDD con los valores\n-   `sortByKey()` devuelve un RDD clave/valor con las claves ordenadas\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:50 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eTransformaciones sobre claves o valores\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003ekeys()\u003c/code\u003e devuelve un RDD con las claves\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003evalues()\u003c/code\u003e devuelve un RDD con los valores\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003esortByKey()\u003c/code\u003e devuelve un RDD clave/valor con las claves ordenadas\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541077175_-411406893",
      "id": "20170708-191117_1364066341",
      "dateCreated": "Jul 8, 2017 7:11:17 PM",
      "dateStarted": "Jul 8, 2017 7:18:10 PM",
      "dateFinished": "Jul 8, 2017 7:18:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nprint(\"RDD completo: {0:\u003e46s}\".format(prdd.collect()))\nprint(\"RDD con las claves: {0:\u003e25s}\".format(prdd.keys().collect()))\nprint(\"RDD con los valores: {0:\u003e18}\".format(prdd.values().collect()))\nprint(\"RDD con las claves ordenadas: {0}\".format(prdd.sortByKey().collect()))",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "RDD completo: [(\u0027a\u0027, 2), (\u0027b\u0027, 5), (\u0027a\u0027, 8), (\u0027b\u0027, 6), (\u0027b\u0027, 2)]\nRDD con las claves: [\u0027a\u0027, \u0027b\u0027, \u0027a\u0027, \u0027b\u0027, \u0027b\u0027]\nRDD con los valores:    [2, 5, 8, 6, 2]\nRDD con las claves ordenadas: [(\u0027a\u0027, 2), (\u0027a\u0027, 8), (\u0027b\u0027, 5), (\u0027b\u0027, 6), (\u0027b\u0027, 2)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d18",
            "http://10.0.2.15:4040/jobs/job?id\u003d19",
            "http://10.0.2.15:4040/jobs/job?id\u003d20",
            "http://10.0.2.15:4040/jobs/job?id\u003d21",
            "http://10.0.2.15:4040/jobs/job?id\u003d22",
            "http://10.0.2.15:4040/jobs/job?id\u003d23"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541287072_-577524305",
      "id": "20170708-191447_687177311",
      "dateCreated": "Jul 8, 2017 7:14:47 PM",
      "dateStarted": "Jun 3, 2023 4:11:02 AM",
      "dateFinished": "Jun 3, 2023 4:11:04 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `mapValues(func)` devuelve un RDD aplicando una función sobre los valores\n-   `flatMapValues(func)` devuelve un RDD aplicando una función sobre los valores y “aplanando” la salida",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003emapValues(func)\u003c/code\u003e devuelve un RDD aplicando una función sobre los valores\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eflatMapValues(func)\u003c/code\u003e devuelve un RDD aplicando una función sobre los valores y “aplanando” la salida\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541317279_1842222825",
      "id": "20170708-191517_765834006",
      "dateCreated": "Jul 8, 2017 7:15:17 PM",
      "dateStarted": "Jul 8, 2017 7:40:20 PM",
      "dateFinished": "Jul 8, 2017 7:40:20 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nmapv \u003d prdd.mapValues(lambda x: (x, 10*x))\nprint(mapv.collect())\n\nfmapv \u003d prdd.flatMapValues(lambda x: (x, 10*x))\nprint(fmapv.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (2, 20)), (\u0027b\u0027, (5, 50)), (\u0027a\u0027, (8, 80)), (\u0027b\u0027, (6, 60)), (\u0027b\u0027, (2, 20))]\n[(\u0027a\u0027, 2), (\u0027a\u0027, 20), (\u0027b\u0027, 5), (\u0027b\u0027, 50), (\u0027a\u0027, 8), (\u0027a\u0027, 80), (\u0027b\u0027, 6), (\u0027b\u0027, 60), (\u0027b\u0027, 2), (\u0027b\u0027, 20)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d24",
            "http://10.0.2.15:4040/jobs/job?id\u003d25"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541356839_-1517157740",
      "id": "20170708-191556_1332053395",
      "dateCreated": "Jul 8, 2017 7:15:56 PM",
      "dateStarted": "Jun 3, 2023 4:11:03 AM",
      "dateFinished": "Jun 3, 2023 4:11:04 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Transformaciones sobre dos RDDs clave/valor\nCombinan dos RDDs de tipo clave/valor para obtener un tercer RDD.",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eTransformaciones sobre dos RDDs clave/valor\u003c/h3\u003e\n\u003cp\u003eCombinan dos RDDs de tipo clave/valor para obtener un tercer RDD.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541445359_-1990860257",
      "id": "20170708-191725_164724394",
      "dateCreated": "Jul 8, 2017 7:17:25 PM",
      "dateStarted": "Jul 10, 2017 5:22:11 PM",
      "dateFinished": "Jul 10, 2017 5:22:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n`join`/`leftOuterJoin`/`rightOuterJoin`/`fullOuterJoin` realizan inner/outer/full joins entre los dos RDDs",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:33:02 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e\u003ccode\u003ejoin\u003c/code\u003e/\u003ccode\u003eleftOuterJoin\u003c/code\u003e/\u003ccode\u003erightOuterJoin\u003c/code\u003e/\u003ccode\u003efullOuterJoin\u003c/code\u003e realizan inner/outer/full joins entre los dos RDDs\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541557149_1518201309",
      "id": "20170708-191917_1589064380",
      "dateCreated": "Jul 8, 2017 7:19:17 PM",
      "dateStarted": "Jul 8, 2017 7:40:35 PM",
      "dateFinished": "Jul 8, 2017 7:40:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd1 \u003d sc.parallelize([(\"a\", 2), (\"b\", 5), (\"a\", 8)]).cache()\nrdd2 \u003d sc.parallelize([(\"c\", 7), (\"a\", 1)]).cache()\n\nrdd3 \u003d rdd1.join(rdd2)\n\nprint(rdd3.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (2, 1)), (\u0027a\u0027, (8, 1))]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d26"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541592627_-684070746",
      "id": "20170708-191952_936041351",
      "dateCreated": "Jul 8, 2017 7:19:52 PM",
      "dateStarted": "Jun 3, 2023 4:11:04 AM",
      "dateFinished": "Jun 3, 2023 4:11:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd3 \u003d rdd1.leftOuterJoin(rdd2)\n\nprint(rdd3.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (2, 1)), (\u0027a\u0027, (8, 1)), (\u0027b\u0027, (5, None))]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d27"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541616071_778221905",
      "id": "20170708-192016_18816027",
      "dateCreated": "Jul 8, 2017 7:20:16 PM",
      "dateStarted": "Jun 3, 2023 4:11:05 AM",
      "dateFinished": "Jun 3, 2023 4:11:07 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd3 \u003d rdd1.rightOuterJoin(rdd2)\n\nprint(rdd3.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (2, 1)), (\u0027a\u0027, (8, 1)), (\u0027c\u0027, (None, 7))]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d28"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541705664_-444186647",
      "id": "20170708-192145_997237677",
      "dateCreated": "Jul 8, 2017 7:21:45 PM",
      "dateStarted": "Jun 3, 2023 4:11:07 AM",
      "dateFinished": "Jun 3, 2023 4:11:08 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd3 \u003d rdd1.fullOuterJoin(rdd2)\n\nprint(rdd3.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (2, 1)), (\u0027a\u0027, (8, 1)), (\u0027c\u0027, (None, 7)), (\u0027b\u0027, (5, None))]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d29"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541811347_-414440033",
      "id": "20170708-192331_430218468",
      "dateCreated": "Jul 8, 2017 7:23:31 PM",
      "dateStarted": "Jun 3, 2023 4:11:07 AM",
      "dateFinished": "Jun 3, 2023 4:11:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `subtractByKey` elimina elementos con una clave presente en otro RDD",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003esubtractByKey\u003c/code\u003e elimina elementos con una clave presente en otro RDD\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541829552_1366593274",
      "id": "20170708-192349_567995858",
      "dateCreated": "Jul 8, 2017 7:23:49 PM",
      "dateStarted": "Jul 8, 2017 7:24:32 PM",
      "dateFinished": "Jul 8, 2017 7:24:32 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd3 \u003d rdd1.subtractByKey(rdd2)\n\nprint(rdd3.collect())",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027b\u0027, 5)]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d30"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499541872724_1673900376",
      "id": "20170708-192432_1212352299",
      "dateCreated": "Jul 8, 2017 7:24:32 PM",
      "dateStarted": "Jun 3, 2023 4:11:08 AM",
      "dateFinished": "Jun 3, 2023 4:11:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `cogroup` agrupa los datos que comparten la misma clave en ambos RDDs",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:37:11 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003ecogroup\u003c/code\u003e agrupa los datos que comparten la misma clave en ambos RDDs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499541917345_-946963159",
      "id": "20170708-192517_337338238",
      "dateCreated": "Jul 8, 2017 7:25:17 PM",
      "dateStarted": "Jul 8, 2017 7:27:26 PM",
      "dateFinished": "Jul 8, 2017 7:27:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nrdd3 \u003d rdd1.cogroup(rdd2)\n\nprint(rdd3.collect())\n\nmap \u003d rdd3.mapValues(lambda v: [list(l) for l in v]).collectAsMap()\n\nprint(map)",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:52 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[(\u0027a\u0027, (\u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033f91d0\u003e, \u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033fef90\u003e)), (\u0027c\u0027, (\u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033fe410\u003e, \u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033fe290\u003e)), (\u0027b\u0027, (\u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033feb50\u003e, \u003cpyspark.resultiterable.ResultIterable object at 0x7ff4033fe3d0\u003e))]\n{\u0027a\u0027: [[2, 8], [1]], \u0027c\u0027: [[], [7]], \u0027b\u0027: [[5], []]}\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d31",
            "http://10.0.2.15:4040/jobs/job?id\u003d32"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499542046311_1375597385",
      "id": "20170708-192726_248584895",
      "dateCreated": "Jul 8, 2017 7:27:26 PM",
      "dateStarted": "Jun 3, 2023 4:11:09 AM",
      "dateFinished": "Jun 3, 2023 4:11:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Acciones sobre RDDs clave/valor\nSobre los RDDs clave/valor podemos aplicar las acciones para RDDs simples y algunas adicionales.\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:38:30 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eAcciones sobre RDDs clave/valor\u003c/h3\u003e\n\u003cp\u003eSobre los RDDs clave/valor podemos aplicar las acciones para RDDs simples y algunas adicionales.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499542067599_1537743593",
      "id": "20170708-192747_13302338",
      "dateCreated": "Jul 8, 2017 7:27:47 PM",
      "dateStarted": "Jul 8, 2017 7:32:58 PM",
      "dateFinished": "Jul 8, 2017 7:32:58 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `collectAsMap()` obtiene el RDD en forma de mapa",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003ecollectAsMap()\u003c/code\u003e obtiene el RDD en forma de mapa\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499542440894_-884486052",
      "id": "20170708-193400_1679400807",
      "dateCreated": "Jul 8, 2017 7:34:00 PM",
      "dateStarted": "Jul 8, 2017 7:34:50 PM",
      "dateFinished": "Jul 8, 2017 7:34:50 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nprdd \u003d sc.parallelize([(\"a\", 7), (\"b\", 5), (\"a\", 8)]).cache()\n\nrddMap \u003d prdd.collectAsMap()\n\nprint(rddMap)",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "{\u0027a\u0027: 8, \u0027b\u0027: 5}\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d33"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499622889614_-323239726",
      "id": "20170709-175449_337839348",
      "dateCreated": "Jul 9, 2017 5:54:49 PM",
      "dateStarted": "Jun 3, 2023 4:11:10 AM",
      "dateFinished": "Jun 3, 2023 4:11:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `countByKey()` devuelve un mapa indicando el número de ocurrencias de cada clave",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003ecountByKey()\u003c/code\u003e devuelve un mapa indicando el número de ocurrencias de cada clave\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499542378408_59010196",
      "id": "20170708-193258_247625966",
      "dateCreated": "Jul 8, 2017 7:32:58 PM",
      "dateStarted": "Jul 8, 2017 7:33:11 PM",
      "dateFinished": "Jul 8, 2017 7:33:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ncountMap \u003d prdd.countByKey()\n\nprint(countMap)",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "defaultdict(\u003ctype \u0027int\u0027\u003e, {\u0027a\u0027: 2, \u0027b\u0027: 1})\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://10.0.2.15:4040/jobs/job?id\u003d34"
          ],
          "interpreterSettingId": "2CET3TKHW"
        }
      },
      "apps": [],
      "jobName": "paragraph_1499542391811_512475907",
      "id": "20170708-193311_1223398973",
      "dateCreated": "Jul 8, 2017 7:33:11 PM",
      "dateStarted": "Jun 3, 2023 4:11:10 AM",
      "dateFinished": "Jun 3, 2023 4:11:11 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   `lookup(key)` devuelve una lista con los valores asociados con una clave",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003elookup(key)\u003c/code\u003e devuelve una lista con los valores asociados con una clave\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499542486509_773274365",
      "id": "20170708-193446_1844221283",
      "dateCreated": "Jul 8, 2017 7:34:46 PM",
      "dateStarted": "Jul 8, 2017 7:36:54 PM",
      "dateFinished": "Jul 8, 2017 7:36:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nlistA \u003d prdd.lookup(\u0027a\u0027)\n\nprint(listA)",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:46:50 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": "org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (Write failed)",
      "apps": [],
      "jobName": "paragraph_1499542613974_-1942516524",
      "id": "20170708-193653_1520387021",
      "dateCreated": "Jul 8, 2017 7:36:53 PM",
      "dateStarted": "Jun 3, 2023 4:46:50 AM",
      "dateFinished": "Jun 3, 2023 4:46:50 AM",
      "status": "ERROR",
      "errorMessage": "java.net.SocketException: Broken pipe (Write failed)\n\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:115)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:161)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)\n\tat org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:145)\n\tat org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:202)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1133)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:992)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext.write(RemoteInterpreterContext.java:882)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6777)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6700)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args.write(RemoteInterpreterService.java:6627)\n\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.send_interpret(RemoteInterpreterService.java:268)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:257)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:374)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:95)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:407)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:181)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## Tarea - Número de citas de patentes\n\nEscribir un programa PySpark que, a partir del fichero apat63_99.txt, obtenga, para cada país de invención (campo \"COUNTRY\" del fichero), el número medio de reivindicaciones (campo \"CLAIMS\" del fichero) de sus patentes.\n\nPreguntas de esta tarea\n- ¿Cuál es el número medio de claims para España (código de país \"ES\")?\n- ¿Cuál es el número medio de claims para Argentina (código de país \"AR\")?\n- ¿Cuál es el número medio de claims para México (código de país \"MX\")?\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:45:11 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTarea - Número de citas de patentes\u003c/h2\u003e\n\u003cp\u003eEscribir un programa PySpark que, a partir del fichero apat63_99.txt, obtenga, para cada país de invención (campo \u0026ldquo;COUNTRY\u0026rdquo; del fichero), el número medio de reivindicaciones (campo \u0026ldquo;CLAIMS\u0026rdquo; del fichero) de sus patentes.\u003c/p\u003e\n\u003cp\u003ePreguntas de esta tarea\u003cbr/\u003e- ¿Cuál es el número medio de claims para España (código de país \u0026ldquo;ES\u0026rdquo;)?\u003cbr/\u003e- ¿Cuál es el número medio de claims para Argentina (código de país \u0026ldquo;AR\u0026rdquo;)?\u003cbr/\u003e- ¿Cuál es el número medio de claims para México (código de país \u0026ldquo;MX\u0026rdquo;)?\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1685767310351_-2107449947",
      "id": "20230603-044150_1955239763",
      "dateCreated": "Jun 3, 2023 4:41:50 AM",
      "dateStarted": "Jun 3, 2023 4:45:11 AM",
      "dateFinished": "Jun 3, 2023 4:45:18 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\npatentes\u003dsc.textFile(\"../datos/cite75_99.txt\")\npatentes.take(10)\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:46:43 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": "org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (Write failed)",
      "apps": [],
      "jobName": "paragraph_1685767523256_1606265217",
      "id": "20230603-044523_1551645448",
      "dateCreated": "Jun 3, 2023 4:45:23 AM",
      "dateStarted": "Jun 3, 2023 4:46:43 AM",
      "dateFinished": "Jun 3, 2023 4:46:43 AM",
      "status": "ERROR",
      "errorMessage": "java.net.SocketException: Broken pipe (Write failed)\n\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:115)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:161)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)\n\tat org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:145)\n\tat org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:202)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1133)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:992)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext.write(RemoteInterpreterContext.java:882)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6777)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6700)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args.write(RemoteInterpreterService.java:6627)\n\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.send_interpret(RemoteInterpreterService.java:268)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:257)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:374)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:95)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:407)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:181)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### TAREA: Obtener las citas recibidas\n\nEscribir un programa PySpark que, a partir del fichero cite75_99.txt, obtenga el número de citas que recibe cada patente.\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eTAREA: Obtener las citas recibidas\u003c/h3\u003e\n\u003cp\u003eEscribir un programa PySpark que, a partir del fichero cite75_99.txt, obtenga el número de citas que recibe cada patente.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499542637943_1621843259",
      "id": "20170708-193717_1780377850",
      "dateCreated": "Jul 8, 2017 7:37:17 PM",
      "dateStarted": "Jul 13, 2017 12:30:30 PM",
      "dateFinished": "Jul 13, 2017 12:30:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:54 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1499774960501_522204624",
      "id": "20170711-120920_1650903483",
      "dateCreated": "Jul 11, 2017 12:09:20 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### TAREA: Número medio de reivindicaciones por país.\n\nEscribir un programa PySpark que, a partir del fichero apat63_99.txt, obtenga, para cada país de invención, el número medio de reivindicaciones de sus patentes.\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:54 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eTAREA: Número medio de reivindicaciones por país.\u003c/h3\u003e\n\u003cp\u003eEscribir un programa PySpark que, a partir del fichero apat63_99.txt, obtenga, para cada país de invención, el número medio de reivindicaciones de sus patentes.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1499707365327_-501105315",
      "id": "20170710-172245_301565319",
      "dateCreated": "Jul 10, 2017 5:22:45 PM",
      "dateStarted": "Jul 23, 2017 11:20:34 AM",
      "dateFinished": "Jul 23, 2017 11:20:34 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "Jun 3, 2023 4:09:54 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1499710927670_542400456",
      "id": "20170710-182207_475616381",
      "dateCreated": "Jul 10, 2017 6:22:07 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Curso Spark/04 - RDDs con pares clave-valor",
  "id": "2CNB7X8GR",
  "angularObjects": {
    "2CCY33GTB:shared_process": [],
    "2CCQCYKJM:shared_process": [],
    "2CD8VB8N5:shared_process": [],
    "2CEZ3N4ZK:shared_process": [],
    "2CCN184W1:shared_process": [],
    "2CCTDCCB9:shared_process": [],
    "2CBRCMJB7:shared_process": [],
    "2CDTHYD1N:shared_process": [],
    "2CD85MNWZ:shared_process": [],
    "2CEM88R8V:shared_process": [],
    "2CBSSQJJR:shared_process": [],
    "2CBG9JDC9:shared_process": [],
    "2CBJUH5Z5:shared_process": [],
    "2CET3TKHW:shared_process": [],
    "2CF1VUR2D:shared_process": [],
    "2CCZDD8PX:shared_process": [],
    "2CESEPECG:shared_process": [],
    "2CCZGPF6E:shared_process": []
  },
  "config": {},
  "info": {}
}