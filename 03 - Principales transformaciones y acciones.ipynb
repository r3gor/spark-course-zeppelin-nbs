{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones elemento-a-elemento\n",
    "======================================\n",
    "\n",
    "#### Generan un nuevo RDD a partir de uno dado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `filter(func)` filtra los elementos de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# Obtener los valores positivos de un rango de números\n",
    "from __future__ import print_function\n",
    "from test_helper import Test\n",
    "rdd = sc.parallelize(xrange(-5,5))          # Rango [-5, 5)\n",
    "filtered_rdd = rdd.filter(lambda x: x >= 0)   # Devuelve los positivos\n",
    "\n",
    "Test.assertEquals(filtered_rdd.collect(), [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "// Obtener los valores positivos de un rango de números\n",
    "val rdd = sc.parallelize(-5 to 5)         // Rango [-5, 5]\n",
    "val filtered_rdd = rdd.filter(x => x>=0)  // Devuelve los positivos\n",
    "\n",
    "assert(filtered_rdd.collect().sameElements(Array(0, 1, 2, 3, 4, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "-   `map(func)` aplica una función a los elementos de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# Ejemplo en PySpark\n",
    "# Añade 1 a cada elemento del RDD\n",
    "# Para cada elemento, obtiene una tupla (x, x**2)\n",
    "def add1(x):\n",
    "    return(x+1)\n",
    "\n",
    "squared_rdd = (filtered_rdd\n",
    "               .map(add1)                 # Añade 1 a cada elemento del RDD\n",
    "               .map(lambda x: (x, x*x)))  # Para cada elemento, obtén una tupla (x, x**2)\n",
    "\n",
    "Test.assertEquals(squared_rdd.collect(), [(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "/* Añade 1 a cada elemento del RDD\n",
    "   Para cada elemento, obtén una tupla (x, x**2) */\n",
    "def add1(x: Int): Int = return(x+1)\n",
    "\n",
    "val squared_rdd = (filtered_rdd\n",
    "               .map(add1)\n",
    "               .map(x => (x, x*x))) \n",
    "               \n",
    "assert(squared_rdd.collect().sameElements(Array((1,1), (2,4), (3,9), (4,16), (5,25), (6,36))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `flatMap(func)` igual que `map`, pero “aplana” la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "squaredflat_rdd = (filtered_rdd\n",
    "                   .map(add1)\n",
    "                   .flatMap(lambda x: (x, x*x)))  # Da la salida en forma de lista\n",
    "                   \n",
    "Test.assertEquals(squaredflat_rdd.collect(), [1, 1, 2, 4, 3, 9, 4, 16, 5, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val squaredflat_rdd = (filtered_rdd\n",
    "                       .map(add1)\n",
    "                       .flatMap(x => List(x, x*x)))  // Da la salida en forma de lista\n",
    "                       \n",
    "assert(squaredflat_rdd.collect().sameElements(Array(1, 1, 2, 4, 3, 9, 4, 16, 5, 25, 6, 36)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `sample(withReplacement, fraction, seed=None)` devuelve una muestra del RDD\n",
    "    - `withReplacement` - si True, cada elemento puede aparecer varias veces en la muestra\n",
    "    - `fraction` - tamaño esperado de la muestra como una fracción del tamaño del RDD \n",
    "        -  **sin reemplazo**: probabilidad de seleccionar un elemento, su valor debe ser [0, 1]\n",
    "        -  **con reemplazo**: número esperado de veces que se escoge un elemento, su valor debe ser >= 0\n",
    "    - `seed` - semilla para el generador de números aleatorios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "srdd1 = squaredflat_rdd.sample(False, 0.5)\n",
    "srdd2 = squaredflat_rdd.sample(True, 2)\n",
    "srdd3 = squaredflat_rdd.sample(False, 0.8, 14)\n",
    "print('s1={0}\\ns2={1}\\ns3={2}'.format(srdd1.collect(), srdd2.collect(), srdd3.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val s1 = squaredflat_rdd.sample(false, 0.5).collect()\n",
    "val s2 = squaredflat_rdd.sample(true, 2).collect()\n",
    "val s3 = squaredflat_rdd.sample(false, 0.8).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `distinct()` devuelve un nuevo RDD sin duplicados\n",
    "    - El orden de la salida no está definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "distinct_rdd = squaredflat_rdd.distinct()\n",
    "print(distinct_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val distinct_rdd = squaredflat_rdd.distinct()\n",
    "println(distinct_rdd.collect().mkString(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `groupBy(func)` devuelve un RDD con los datos agrupados en formato clave/valor, \n",
    "usando una función para obtener la clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "grouped_rdd = distinct_rdd.groupBy(lambda x: x%3)\n",
    "print(grouped_rdd.collect())\n",
    "print([(x,sorted(y)) for (x,y) in grouped_rdd.collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val grouped_rdd = distinct_rdd.groupBy(x => x%3)\n",
    "val grouped = grouped_rdd.collect()\n",
    "grouped.foreach(f => println(f._1+\" (\"+f._2.mkString(\" \")+\") \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones sobre dos RDDs\n",
    "\n",
    "Operaciones tipo conjunto sobre dos RDDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `rdda.union(rddb)` devuelve un RDD con los datos de los dos de partida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdda = sc.parallelize(['a', 'b', 'c'])\n",
    "rddb = sc.parallelize(['c', 'd', 'e'])\n",
    "rddu = rdda.union(rddb)\n",
    "Test.assertEquals(rddu.collect(),['a', 'b', 'c', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rdda = sc.parallelize(List('a', 'b', 'c'))\n",
    "val rddb = sc.parallelize(List('c', 'd', 'e'))\n",
    "val rddu = rdda.union(rddb)\n",
    "assert(rddu.collect().sameElements(Array('a', 'b', 'c', 'c', 'd', 'e')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rdda.intersection(rddb)` devuelve un RDD con los datos comunes en ambos RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rddi = rdda.intersection(rddb)\n",
    "Test.assertEquals(rddi.collect(),['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rddi = rdda.intersection(rddb)\n",
    "assert(rddi.collect().sameElements(Array('c')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `rdda.subtract(rddb)` devuelve un RDD con los datos del primer RDD menos los del segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdds = rdda.subtract(rddb)\n",
    "Test.assertEquals(rdds.collect(), ['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rdds = rdda.subtract(rddb)\n",
    "assert(rdds.collect().sameElements(Array('a', 'b')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rdda.cartesian(rddb)` producto cartesiano de ambos RDDs (operación muy costosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rddc = rdda.cartesian(rddb)\n",
    "Test.assertEquals(rddc.collect(), \n",
    "                  [('a','c'),('a','d'),('a','e'),('b','c'),('b','d'),('b','e'),('c','c'), ('c','d'), ('c','e')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rddc = rdda.cartesian(rddb)\n",
    "assert(rddc.collect().sameElements( \n",
    "                  Array(('a','c'),('a','d'),('a','e'),('b','c'),('b','d'),('b','e'),('c','c'), ('c','d'), ('c','e'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acciones sobre RDDs simples\n",
    "======================================\n",
    "\n",
    "#### Obtienen datos (simples o compuestos) a partir de un RDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principales acciones de agregación: `reduce` y `fold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `reduce(op)` combina los elementos de un RDD en paralelo, aplicando un operador\n",
    "    - El operador de reducción debe ser un *monoide conmutativo* (operador binario asociativo y conmutativo)\n",
    "    - Primero se realiza la redución a nivel de partición y luego se van reduciendo los valores intermedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(xrange(1,10), 8)  # rango [1, 10)\n",
    "print(rdd.glom().collect())\n",
    "\n",
    "# Reducción con una función lambda\n",
    "p = rdd.reduce(lambda x,y: x*y) # r = 1*2*3*4*5*6*7*8*9 = 362880\n",
    "print(\"1*2*3*4*5*6*7*8*9 = {0}\".format(p))\n",
    "\n",
    "# Reducción con un operador predefinido\n",
    "from operator import add\n",
    "s = rdd.reduce(add) # s = 1+2+3+4+5+6+7+8+9 = 45\n",
    "print(\"1+2+3+4+5+6+7+8+9 = {0}\".format(s))\n",
    "\n",
    "# Prueba con un operador no conmutativo\n",
    "p = rdd.reduce(lambda x,y: x-y) # r = 1-2-3-4-5-6-7-8-9 = -43\n",
    "print(\"1-2-3-4-5-6-7-8-9 = {0}\".format(p))\n",
    "\n",
    "# No funciona con RDDs vacíos\n",
    "#sc.parallelize([]).reduce(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rdd = sc.parallelize(1 to 9)    // rango [1, 9]\n",
    "val l = rdd.glom().collect()\n",
    "\n",
    "// Reducciones conn funciones anónimas\n",
    "val p = rdd.reduce((x,y) => x*y)    // r = 1*2*3*4*5*6*7*8*9 = 362880\n",
    "val s = rdd.reduce(_+_)             // s = 1+2+3+4+5+6+7+8+9 = 45\n",
    "\n",
    "// No funciona con RDDs vacíos\n",
    "//sc.parallelize(List[Int]()).reduce(_+_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `fold(cero, op)` versión general de `reduce`: \n",
    "    - Debemos proporcionar un valor inicial `cero` para el operador\n",
    "    - El valor inicial debe ser el valor identidad para el operador (p.e. 0 para suma; 1 para producto, o una lista vacía para concatenación de listas)\n",
    "        - Permite utilizar RDDs vacíos\n",
    "    - La función `op` debe ser un monoide conmutativo para garantizar un resultado consistente\n",
    "        - Comportamiento diferente a las operaciones `fold` de lenguajes como Scala\n",
    "        - El operador se aplica a nivel de partición (usando `cero` como valor inicial), y finalmente entre todas las particiones (usando `cero`de nuevo)\n",
    "        - Para operadores no conmutativos el resultado podría ser diferente del obtenido mediante un `fold` secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([range(1,5), range(-10,-3), ['a', 'b', 'c']])\n",
    "print(rdd.glom().collect())\n",
    "\n",
    "f = rdd.fold([], lambda x,y: x+y)\n",
    "print(f)\n",
    "\n",
    "# Se puede hacer un fold de un RDD vacío\n",
    "sc.parallelize([]).fold(0, add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val rdd = sc.parallelize(List(List.range(1,5), List.range(-10,-3), List('a', 'b', 'c')))\n",
    "val l = rdd.glom().collect()\n",
    "\n",
    "val f = rdd.fold(List[AnyVal]())((l1, l2) => l1 ::: l2)\n",
    "println(f)\n",
    "\n",
    "// Se puede hacer un fold de un RDD vacío\n",
    "sc.parallelize(List()).fold(0)(_+_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "// Ejemplo de comportamiento extraño\n",
    "// Comportamiento en secuencial\n",
    "val a = Array(2, 3)\n",
    "val f = a.fold(0)((p, v) => p+v*v) // f = (0 + 2*2) + (3*3) = 13\n",
    "\n",
    "// Comportamiento en paralelo\n",
    "val rdda = sc.parallelize(a, 2)\n",
    "val fa = rdda.fold(0)((p, v) => p+v*v)  \n",
    "// Partición 0: fa0 = (0 + 2*2) = 4\n",
    "// Partición 1: fa1 = (0 + 3*3) = 9\n",
    "// fold final: fa = (0 + fa0*fa0) + (fa1*fa1) = (0 + 4*4) + (9*9) = 97\n",
    "\n",
    "// El resultado puede variar con el número de particiones\n",
    "val rdda = sc.parallelize(a, 1)\n",
    "val fa = rdda.fold(0)((p, v) => p+v*v)\n",
    "// ¿Por qué obtenemos este valor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otras acciones de agregación: `aggregate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - `aggregate(cero,seqOp,combOp)`: Devuelve una colección agregando los elementos del RDD usando dos funciones:\n",
    "    1. `seqOp` -  agregación a nivel de partición: se crea un acumulador por partición (inicializado a `cero`) y se agregan los valores de la partición en el acumulador\n",
    "    2. `combOp` - agregación entre particiones: se agregan los acumuladores de todas las particiones\n",
    "    -  Ambas agregaciones usan un valor inicial `cero` (similar al caso de `fold`).\n",
    " - Versión general de `reduce` y `fold`    \n",
    " - La primera función (`seqOp`) puede devolver un tipo, U, diferente del tipo T de los elementos del RDD\n",
    "    - `seqOp` agregar datos de tipo T y devuelve un tipo U\n",
    "    - `combOp` agrega datos de tipo U\n",
    "    - `cero` debe ser de tipo U\n",
    " - Permite devolver un tipo diferente al de los elementos del RDD de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "l = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "rdd = sc.parallelize(l)\n",
    "\n",
    "# acc es una tupla de tres elementos (List, Double, Int)\n",
    "# En el primer elemento de acc (lista) le concatenamos los elementos del RDD al cuadrado\n",
    "# en el segundo, acumulamos los elementos del RDD usando multiplicación\n",
    "# y en el tercero, contamos los elementos del RDD\n",
    "seqOp  = (lambda acc, val: (acc[0]+[val*val], \n",
    "                            acc[1]*val, \n",
    "                            acc[2]+1))\n",
    "# Para cada partición se genera una tupla tipo acc\n",
    "# En esta operación se combinan los tres elementos de las tuplas\n",
    "combOp = (lambda acc1, acc2: (acc1[0]+acc2[0], \n",
    "                              acc1[1]*acc2[1], \n",
    "                              acc1[2]+acc2[2]))\n",
    "                              \n",
    "a = rdd.aggregate(([], 1., 0), seqOp, combOp) \n",
    "\n",
    "print(a)\n",
    "\n",
    "Test.assertEquals(a[1], 8.*7.*6.*5.*4.*3.*2.*1.)\n",
    "Test.assertEquals(a[2], len(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val l = List(1, 2, 3, 4, 5, 6, 7, 8)\n",
    "val rdd = sc.parallelize(l)\n",
    "val dl = rdd.glom.collect()\n",
    "\n",
    "// acc es una tupla de tres elementos (List[Int], Double, Int)\n",
    "// En el primer elemento de acc, insertamos por el principio los elementos del RDD al cuadrado\n",
    "// en el segundo, acumulamos los elementos del RDD usando multiplicación\n",
    "// y en el tercero, contamos los elementos del RDD\n",
    "def seqOp(acum: (List[Int], Double, Int), valor: Int)  = ((valor*valor) :: acum._1, \n",
    "                                                          acum._2 * valor, \n",
    "                                                          acum._3 + 1)\n",
    "// Para cada partición se genera una tupla tipo acc\n",
    "// En esta operación se combinan los tres elementos de las tuplas\n",
    "def combOp(acum1: (List[Int], Double, Int), acum2: (List[Int], Double, Int)) = (acum1._1 ::: acum2._1, \n",
    "                                                                                acum1._2 * acum2._2, \n",
    "                                                                                acum1._3 + acum2._3)\n",
    "\n",
    "val a = rdd.aggregate((List[Int](), 1.0, 0))(seqOp, combOp)\n",
    "\n",
    "assert(a._2 == (8.0*7.0*6.0*5.0*4.0*3.0*2.0*1.0))\n",
    "assert(a._3 == l.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acciones para contar elementos\n",
    "- `count()` devuelve un entero con el número exacto de elementos del RDD\n",
    "- `countApprox(timeout, confidence=0.95)` versión aproximada de `count()` que devuelve un resultado potencialmente incompleto en un tiempo máximo, incluso si no todas las tareas han finalizado. (Experimental).\n",
    "    - `timeout` es un entero largo e indica el tiempo en milisegundos\n",
    "    - `confidence` probabilidad de obtener el valor real. Si `confidence` es 0.90 quiere decir que si se ejecuta múltiples veces, se espera que el 90% de ellas se obtenga el valor correcto. Valor [0,1]\n",
    "- `countApproxDistinct(relativeSD=0.05)` devuelve una estimación del número de elementos diferentes del RDD.  (Experimental).\n",
    "    - `relativeSD` – exactitud relativa (valores más pequeños implican menor error, pero requieren más memoria; debe ser mayor que 0.000017).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([i % 20 for i in xrange(10000)], 16)\n",
    "print(\"Número total de elementos: {0}\".format(rdd.count()))\n",
    "print(\"Número de elementos distintos: {0}\".format(rdd.distinct().count()))\n",
    "\n",
    "print(\"Número total de elementos (aprox.): {0}\".format(rdd.countApprox(1, 0.4)))\n",
    "print(\"Número de elementos distintos (approx.): {0}\".format(rdd.countApproxDistinct(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `countByValue()` devuelve el número de apariciones de cada elemento del RDD como un mapa (o diccionario) de tipo clave/valor\n",
    "    - Las claves son los elementos del RDD y cada valor, el número de ocurrencias de la clave asociada al mismo      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(list(\"abracadabra\")).cache()\n",
    "mimapa = rdd.countByValue()\n",
    "\n",
    "print(type(mimapa))\n",
    "print(mimapa.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acciones para obtener valores\n",
    "- Estos métodos deben usarse con cuidado, si el resultado esperado es muy grande puede saturar la memoria del driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `collect()` devuelve una lista con todos los elementos del RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "lista = rdd.collect()\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `take(n)` devuelve los `n` primeros elementos del RDD\n",
    "-   `takeSample(withRep, n, [seed])` devuelve `n` elementos aleatorios del RDD\n",
    "    - `withRep`: si True, en la muestra puede aparecer el mismo elemento varias veces\n",
    "    - `seed`: semilla para el generador de números aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "t = rdd.take(4)\n",
    "print(t)\n",
    "s = rdd.takeSample(False, 4)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `top(n)` devuelve una lista con los primeros `n` elementos del RDD ordenados en orden descendente\n",
    "-   `takeOrdered(n,[orden])` devuelve una lista con los primeros `n` elementos del RDD en orden ascendente (opuesto a `top`), o siguiendo el orden indicado en la función opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([8, 4, 2, 9, 3, 1, 10, 5, 6, 7]).cache()\n",
    "\n",
    "print(\"4 elementos más grandes: {0}\".format(rdd.top(4)))\n",
    "\n",
    "print(\"4 elementos más pequeños: {0}\".format(rdd.takeOrdered(4)))\n",
    "\n",
    "print(\"4 elementos más grandes: {0}\".format(rdd.takeOrdered(4, lambda x: -x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
